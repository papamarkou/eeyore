{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of MLP log-likelihood for binary classification\n",
    "\n",
    "Confirm PyTorch and manually coded MLP log-likelihood coincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from eeyore.models.mlp import Hyperparameters, MLP\n",
    "from eeyore.data import XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-likelihood using eeyore API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load XOR data\n",
    "\n",
    "xor = XOR(dtype=torch.float64)\n",
    "\n",
    "data = xor.data\n",
    "labels = xor.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup MLP model\n",
    "\n",
    "hparams = Hyperparameters([2, 2, 1])\n",
    "model = MLP(hparams=hparams, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix model parameters\n",
    "\n",
    "theta = torch.tensor([1.1, -2.9, -0.4, 0.8, 4.3, 9.2, 4.44, -3.4, 7.2], dtype=torch.float64)\n",
    "model.set_params(theta.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-likelihood using eeyore API version\n",
    "\n",
    "result01 = model.log_lik(data, labels)\n",
    "result01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-likelihood using Pytorch loss and cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9997],\n",
       "        [0.9994],\n",
       "        [0.9997],\n",
       "        [0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute model output using Pytorch forward() method\n",
    "\n",
    "out = model(data)\n",
    "# out = model.forward(data)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define logit loss\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "loss = criterion(out, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define logit function\n",
    "\n",
    "def logit(p):\n",
    "    return torch.log(p/(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-likelihood using Pytorch binary_cross_entropy_with_logits\n",
    "\n",
    "result02a = -F.binary_cross_entropy_with_logits(logit(out), labels, reduction='sum')\n",
    "result02a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-likelihood using Pytorch binary_cross_entropy\n",
    "\n",
    "result02b = -F.binary_cross_entropy(out, labels, reduction='sum')\n",
    "result02b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-likelihood manually given Pytorch forward output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define sigmoid function\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MLP log-lik\n",
    "\n",
    "def log_lik(g, y):\n",
    "    term = y * torch.log(sigmoid(g)) + (1-y) * torch.log(1-sigmoid(g))\n",
    "    return torch.sum(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-lik\n",
    "\n",
    "result03 = log_lik(logit(out), labels)\n",
    "result03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-likelihood similarly to model.log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9997],\n",
       "        [0.9994],\n",
       "        [0.9997],\n",
       "        [0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print output from forward pass of MLP model\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MLP forward01\n",
    "\n",
    "def forward01(x):\n",
    "    h = x\n",
    "    for fc, activation in zip(model.fc_layers, model.hp.activations):\n",
    "        h = activation(fc(h))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9997],\n",
       "        [0.9994],\n",
       "        [0.9997],\n",
       "        [0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP forward01\n",
    "\n",
    "out_of_forward01 = forward01(data)\n",
    "out_of_forward01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-lik given forward01 out\n",
    "\n",
    "result04 = log_lik(logit(out_of_forward01), labels)\n",
    "result04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-likelihood manually by invoking linear layer and activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MLP forward02\n",
    "\n",
    "def forward02(x, num_layers):\n",
    "    h = x\n",
    "    for i in range(num_layers):\n",
    "        h = model.hp.activations[i](model.fc_layers[i](h))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9997],\n",
       "        [0.9994],\n",
       "        [0.9997],\n",
       "        [0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP forward02\n",
    "\n",
    "out_of_forward02 = forward02(data, 2)\n",
    "out_of_forward02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-lik given forward02 out\n",
    "\n",
    "result05 = log_lik(logit(out_of_forward02), labels)\n",
    "result05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-likelihood computing manually linear layers given activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MLP forward03\n",
    "\n",
    "def forward03(x, num_layers):\n",
    "    h = x\n",
    "    for i in range(num_layers):\n",
    "        h = model.hp.activations[i](h @ model.fc_layers[i].weight.t() + model.fc_layers[i].bias)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9997],\n",
       "        [0.9994],\n",
       "        [0.9997],\n",
       "        [0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP forward03\n",
    "\n",
    "out_of_forward03 = forward03(data, 2)\n",
    "out_of_forward03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-lik given forward03 out\n",
    "\n",
    "result06 = log_lik(logit(out_of_forward03), labels)\n",
    "result06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-likelihood fully manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MLP forward04\n",
    "\n",
    "def forward04(x):\n",
    "    w1 = theta[0:4].view(2, 2)\n",
    "    b1 = theta[4:6].view(2)\n",
    "    g1 = x @ w1.t() + b1\n",
    "    h1 = torch.sigmoid(g1)\n",
    "    w2 = theta[6:8].view(1, 2)\n",
    "    b2 = theta[8:9].view(1)\n",
    "    g2 = h1 @ w2.t() + b2\n",
    "    h2 = torch.sigmoid(g2)\n",
    "    \n",
    "    return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9997],\n",
       "        [0.9994],\n",
       "        [0.9997],\n",
       "        [0.9996]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP forward04\n",
    "\n",
    "out_of_forward04 = forward04(data)\n",
    "out_of_forward04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.0859, dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-lik given forward04 out\n",
    "\n",
    "result07 = log_lik(logit(out_of_forward04), labels)\n",
    "result07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out values of all log-lik implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-16.08587869723768,\n",
       " -16.08587869723768,\n",
       " -16.08587869723768,\n",
       " -16.08587869723768,\n",
       " -16.08587869723768,\n",
       " -16.08587869723768,\n",
       " -16.08587869723768,\n",
       " -16.08587869723768]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.data.item() for p in\n",
    "    [result01, result02a, result02b, result03, result04, result05, result06, result07]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

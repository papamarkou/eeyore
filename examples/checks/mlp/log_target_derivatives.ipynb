{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of MLP log-likelihood\n",
    "\n",
    "Confirm PyTorch and manually coded MLP log-likelihood coincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Normal\n",
    "from torch.autograd import grad\n",
    "\n",
    "from eeyore.models.mlp import Hyperparameters, MLP\n",
    "from eeyore.data import XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-target using eeyore API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load XOR data\n",
    "\n",
    "xor = XOR(dtype=torch.float64)\n",
    "\n",
    "data = xor.data\n",
    "labels = xor.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup MLP model\n",
    "\n",
    "hparams = Hyperparameters([2, 2, 1])\n",
    "model = MLP(hparams=hparams, dtype=torch.float64)\n",
    "model.prior = Normal(torch.zeros(9, dtype=torch.float64), 100*torch.ones(9, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix model parameters\n",
    "\n",
    "theta0 = torch.tensor([1.1, -2.9, -0.4, 0.8, 4.3, 9.2, 4.44, -3.4, 7.2], dtype=torch.float64)\n",
    "theta = theta0.clone().detach()\n",
    "model.set_params(theta.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-65.8127, dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-target using eeyore API version\n",
    "\n",
    "lt_result01 = model.log_target(theta, data, labels)\n",
    "lt_result01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-target fully manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(theta, x, y):\n",
    "    w1 = theta[0:4].view(2, 2)\n",
    "    b1 = theta[4:6].view(2)\n",
    "    g1 = x @ w1.t() + b1\n",
    "    h1 = torch.sigmoid(g1)\n",
    "    w2 = theta[6:8].view(1, 2)\n",
    "    b2 = theta[8:9].view(1)\n",
    "    g2 = h1 @ w2.t() + b2\n",
    "    h2 = torch.sigmoid(g2)\n",
    "    \n",
    "    return -F.binary_cross_entropy(h2, y, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    d = Normal(torch.zeros(9, dtype=torch.float64), 100*torch.ones(9, dtype=torch.float64))\n",
    "    return torch.sum(d.log_prob(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_target(theta, x, y):\n",
    "    return log_lik(theta, x, y)+log_prior(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-65.8127, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_result02 = log_target(theta, data, labels)\n",
    "lt_result02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out values of both log-target implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-65.81269034997256, -65.81269034997256]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.data.item() for p in [lt_result01, lt_result02]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad of MLP log-target using eeyore API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "        -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "       dtype=torch.float64, grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "\n",
    "lt_val01 = model.log_target(theta, data, labels)\n",
    "\n",
    "glt_result01 = model.grad_log_target(lt_val01)\n",
    "glt_result01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad of MLP log-target using backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "        -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "\n",
    "lt_val02 = model.log_target(theta, data, labels)\n",
    "\n",
    "lt_val02.backward(retain_graph=True)\n",
    "\n",
    "# Rerun so that it becomes possible to call p.grad.zero_()\n",
    "\n",
    "theta = theta0.clone().detach()\n",
    "\n",
    "lt_val03 = model.log_target(theta, data, labels)\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.grad.zero_()\n",
    "\n",
    "lt_val03.backward()\n",
    "\n",
    "glt_result02 = torch.cat([p.grad.view(-1) for p in model.parameters()])\n",
    "glt_result02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad of MLP log-target calling grad() on manually coded log_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "        -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "theta.requires_grad_(True)\n",
    "\n",
    "lt_val04 = log_target(theta, data, labels)\n",
    "\n",
    "glt_result03, = grad(lt_val04, theta)\n",
    "glt_result03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out values of all grad log-target implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64),\n",
       " tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in [glt_result01, glt_result02, glt_result03]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of grad and of Hessian of MLP log-target\n",
    "\n",
    "Confirm PyTorch and manually coded grad and metric tensor of MLP log-target coincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Normal\n",
    "from torch.autograd import grad\n",
    "\n",
    "from eeyore.data import XOR\n",
    "from eeyore.stats import binary_cross_entropy\n",
    "from eeyore.models.mlp import Hyperparameters, MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-target using eeyore API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load XOR data\n",
    "\n",
    "xor = XOR(dtype=torch.float64)\n",
    "\n",
    "data = xor.data\n",
    "labels = xor.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup MLP model\n",
    "\n",
    "hparams = Hyperparameters([2, 2, 1])\n",
    "model = MLP(hparams=hparams, dtype=torch.float64)\n",
    "model.prior = Normal(torch.zeros(9, dtype=torch.float64), 100*torch.ones(9, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix model parameters\n",
    "\n",
    "theta0 = torch.tensor([1.1, -2.9, -0.4, 0.8, 4.3, 9.2, 4.44, -3.4, 7.2], dtype=torch.float64)\n",
    "theta = theta0.clone().detach()\n",
    "model.set_params(theta.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-65.8127, dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute MLP log-target using eeyore API version\n",
    "\n",
    "lt_result01 = model.log_target(theta, data, labels)\n",
    "lt_result01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-16.0859, dtype=torch.float64, grad_fn=<NegBackward>),\n",
       " tensor(-49.7268, dtype=torch.float64, grad_fn=<SumBackward0>),\n",
       " tensor(-65.8127, dtype=torch.float64, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confirm that log-target is the sum of log-lik and log-prior\n",
    "\n",
    "model.log_lik(data, labels), model.log_prior(), model.log_lik(data, labels)+model.log_prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MLP log-target fully manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(theta, x, y):\n",
    "    w1 = theta[0:4].view(2, 2)\n",
    "    b1 = theta[4:6].view(2)\n",
    "    g1 = x @ w1.t() + b1\n",
    "    h1 = torch.sigmoid(g1)\n",
    "    w2 = theta[6:8].view(1, 2)\n",
    "    b2 = theta[8:9].view(1)\n",
    "    g2 = h1 @ w2.t() + b2\n",
    "    h2 = torch.sigmoid(g2)\n",
    "    \n",
    "    return -binary_cross_entropy(h2, y, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    d = Normal(torch.zeros(9, dtype=torch.float64), 100*torch.ones(9, dtype=torch.float64))\n",
    "    return torch.sum(d.log_prob(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_target(theta, x, y):\n",
    "    return log_lik(theta, x, y)+log_prior(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-65.8127, dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_result02 = log_target(theta, data, labels)\n",
    "lt_result02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out values of both log-target implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-65.81269034997256, -65.81269034997256]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.data.item() for p in [lt_result01, lt_result02]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad of MLP log-target using eeyore API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "        -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "       dtype=torch.float64, grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "\n",
    "lt_val01 = model.log_target(theta, data, labels)\n",
    "\n",
    "glt_result01 = model.grad_log_target(lt_val01)\n",
    "glt_result01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad of MLP log-target using backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "        -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "\n",
    "lt_val02 = model.log_target(theta, data, labels)\n",
    "\n",
    "lt_val02.backward(retain_graph=True)\n",
    "\n",
    "# Rerun so that it becomes possible to call p.grad.zero_()\n",
    "\n",
    "theta = theta0.clone().detach()\n",
    "\n",
    "lt_val03 = model.log_target(theta, data, labels)\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.grad.zero_()\n",
    "\n",
    "lt_val03.backward()\n",
    "\n",
    "glt_result02 = torch.cat([p.grad.view(-1) for p in model.parameters()])\n",
    "glt_result02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad of MLP log-target calling grad() on manually coded log_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "        -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "theta.requires_grad_(True)\n",
    "\n",
    "lt_val04 = log_target(theta, data, labels)\n",
    "\n",
    "glt_result03, = grad(lt_val04, theta)\n",
    "glt_result03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad of MLP log-target calling grad() on manually coded log-lik and log-prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.1114e-01, -3.1070e-01,  2.3002e-04,  2.3006e-04, -3.6932e-01,\n",
       "          5.7329e-04, -1.9094e+00, -1.9983e+00, -1.9984e+00],\n",
       "        dtype=torch.float64),\n",
       " tensor([-1.1000e-04,  2.9000e-04,  4.0000e-05, -8.0000e-05, -4.3000e-04,\n",
       "         -9.2000e-04, -4.4400e-04,  3.4000e-04, -7.2000e-04],\n",
       "        dtype=torch.float64),\n",
       " tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confirm that log-target is the sum of log-lik and log-prior\n",
    "\n",
    "theta = theta0.clone().detach()\n",
    "theta.requires_grad_(True)\n",
    "\n",
    "ll_val = log_lik(theta, data, labels)\n",
    "\n",
    "gll_val, = grad(ll_val, theta)\n",
    "\n",
    "lp_val = log_prior(theta)\n",
    "\n",
    "glp_val, = grad(lp_val, theta)\n",
    "\n",
    "glt_result04 = gll_val+glp_val\n",
    "gll_val, glp_val, glt_result04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out values of all grad log-target implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64),\n",
       " tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64),\n",
       " tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in [glt_result01, glt_result02, glt_result03, glt_result04]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metric of MLP log-target using eeyore API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-65.8127, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor([-3.1125e-01, -3.1041e-01,  2.7002e-04,  1.5006e-04, -3.6975e-01,\n",
       "         -3.4671e-04, -1.9098e+00, -1.9979e+00, -1.9992e+00],\n",
       "        dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([[-2.6380e-01, -2.6390e-01, -2.9198e-08, -2.6460e-08, -2.6390e-01,\n",
       "          -2.9198e-08,  7.0188e-02,  1.2025e-04,  1.2026e-04],\n",
       "         [-2.6390e-01, -2.6322e-01, -2.6460e-08, -9.5428e-08, -2.6332e-01,\n",
       "          -9.5428e-08,  7.0442e-02,  5.6173e-04,  5.6176e-04],\n",
       "         [-2.9198e-08, -2.6460e-08,  3.2999e-04,  2.3013e-04, -2.9198e-08,\n",
       "           2.2999e-04, -2.1572e-07,  6.7431e-05, -2.2279e-07],\n",
       "         [-2.6460e-08, -9.5428e-08,  2.3013e-04,  3.3003e-04, -9.5428e-08,\n",
       "           2.3003e-04, -1.5708e-07,  6.7483e-05, -1.8290e-07],\n",
       "         [-2.6390e-01, -2.6332e-01, -2.9198e-08, -9.5428e-08, -3.2027e-01,\n",
       "          -1.0380e-07,  8.3666e-02,  5.8348e-04,  5.8352e-04],\n",
       "         [-2.9198e-08, -9.5428e-08,  2.2999e-04,  2.3003e-04, -1.0380e-07,\n",
       "           6.7319e-04, -3.8906e-07,  1.6820e-04, -4.1677e-07],\n",
       "         [ 7.0188e-02,  7.0442e-02, -2.1572e-07, -1.5708e-07,  8.3666e-02,\n",
       "          -3.8906e-07,  1.3623e-03,  1.3936e-03,  1.3937e-03],\n",
       "         [ 1.2025e-04,  5.6173e-04,  6.7431e-05,  6.7483e-05,  5.8348e-04,\n",
       "           1.6820e-04,  1.3936e-03,  1.6519e-03,  1.5520e-03],\n",
       "         [ 1.2026e-04,  5.6176e-04, -2.2279e-07, -1.8290e-07,  5.8352e-04,\n",
       "          -4.1677e-07,  1.3937e-03,  1.5520e-03,  1.6521e-03]],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "\n",
    "lt_val05, glt_result05, mlt_result01 = model.upto_metric_log_target(theta, data, labels)\n",
    "lt_val05, glt_result05, mlt_result01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metric of MLP log-target calling grad() on manually coded log_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6380e-01, -2.6390e-01, -2.9198e-08, -2.6460e-08, -2.6390e-01,\n",
       "         -2.9198e-08,  7.0188e-02,  1.2025e-04,  1.2026e-04],\n",
       "        [-2.6390e-01, -2.6322e-01, -2.6460e-08, -9.5428e-08, -2.6332e-01,\n",
       "         -9.5428e-08,  7.0442e-02,  5.6173e-04,  5.6176e-04],\n",
       "        [-2.9198e-08, -2.6460e-08,  3.2999e-04,  2.3013e-04, -2.9198e-08,\n",
       "          2.2999e-04, -2.1572e-07,  6.7431e-05, -2.2279e-07],\n",
       "        [-2.6460e-08, -9.5428e-08,  2.3013e-04,  3.3003e-04, -9.5428e-08,\n",
       "          2.3003e-04, -1.5708e-07,  6.7483e-05, -1.8290e-07],\n",
       "        [-2.6390e-01, -2.6332e-01, -2.9198e-08, -9.5428e-08, -3.2027e-01,\n",
       "         -1.0380e-07,  8.3666e-02,  5.8348e-04,  5.8352e-04],\n",
       "        [-2.9198e-08, -9.5428e-08,  2.2999e-04,  2.3003e-04, -1.0380e-07,\n",
       "          6.7319e-04, -3.8906e-07,  1.6820e-04, -4.1677e-07],\n",
       "        [ 7.0188e-02,  7.0442e-02, -2.1572e-07, -1.5708e-07,  8.3666e-02,\n",
       "         -3.8906e-07,  1.3623e-03,  1.3936e-03,  1.3937e-03],\n",
       "        [ 1.2025e-04,  5.6173e-04,  6.7431e-05,  6.7483e-05,  5.8348e-04,\n",
       "          1.6820e-04,  1.3936e-03,  1.6519e-03,  1.5520e-03],\n",
       "        [ 1.2026e-04,  5.6176e-04, -2.2279e-07, -1.8290e-07,  5.8352e-04,\n",
       "         -4.1677e-07,  1.3937e-03,  1.5520e-03,  1.6521e-03]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta0.clone().detach()\n",
    "theta.requires_grad_(True)\n",
    "\n",
    "lt_val06 = log_target(theta, data, labels)\n",
    "\n",
    "glt_result06, = grad(lt_val06, theta, create_graph=True)\n",
    "\n",
    "hlt_val = []\n",
    "for i in range(9):\n",
    "    deriv_i_wrt_grad = grad(glt_result06[i], theta, retain_graph=True)\n",
    "    hlt_val.append(torch.cat([h.view(-1) for h in deriv_i_wrt_grad]))\n",
    "\n",
    "mlt_result02 = -torch.cat(hlt_val, 0).reshape(9, 9)\n",
    "mlt_result02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out values of both metric log-target implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-2.6380e-01, -2.6390e-01, -2.9198e-08, -2.6460e-08, -2.6390e-01,\n",
       "          -2.9198e-08,  7.0188e-02,  1.2025e-04,  1.2026e-04],\n",
       "         [-2.6390e-01, -2.6322e-01, -2.6460e-08, -9.5428e-08, -2.6332e-01,\n",
       "          -9.5428e-08,  7.0442e-02,  5.6173e-04,  5.6176e-04],\n",
       "         [-2.9198e-08, -2.6460e-08,  3.2999e-04,  2.3013e-04, -2.9198e-08,\n",
       "           2.2999e-04, -2.1572e-07,  6.7431e-05, -2.2279e-07],\n",
       "         [-2.6460e-08, -9.5428e-08,  2.3013e-04,  3.3003e-04, -9.5428e-08,\n",
       "           2.3003e-04, -1.5708e-07,  6.7483e-05, -1.8290e-07],\n",
       "         [-2.6390e-01, -2.6332e-01, -2.9198e-08, -9.5428e-08, -3.2027e-01,\n",
       "          -1.0380e-07,  8.3666e-02,  5.8348e-04,  5.8352e-04],\n",
       "         [-2.9198e-08, -9.5428e-08,  2.2999e-04,  2.3003e-04, -1.0380e-07,\n",
       "           6.7319e-04, -3.8906e-07,  1.6820e-04, -4.1677e-07],\n",
       "         [ 7.0188e-02,  7.0442e-02, -2.1572e-07, -1.5708e-07,  8.3666e-02,\n",
       "          -3.8906e-07,  1.3623e-03,  1.3936e-03,  1.3937e-03],\n",
       "         [ 1.2025e-04,  5.6173e-04,  6.7431e-05,  6.7483e-05,  5.8348e-04,\n",
       "           1.6820e-04,  1.3936e-03,  1.6519e-03,  1.5520e-03],\n",
       "         [ 1.2026e-04,  5.6176e-04, -2.2279e-07, -1.8290e-07,  5.8352e-04,\n",
       "          -4.1677e-07,  1.3937e-03,  1.5520e-03,  1.6521e-03]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[-2.6380e-01, -2.6390e-01, -2.9198e-08, -2.6460e-08, -2.6390e-01,\n",
       "          -2.9198e-08,  7.0188e-02,  1.2025e-04,  1.2026e-04],\n",
       "         [-2.6390e-01, -2.6322e-01, -2.6460e-08, -9.5428e-08, -2.6332e-01,\n",
       "          -9.5428e-08,  7.0442e-02,  5.6173e-04,  5.6176e-04],\n",
       "         [-2.9198e-08, -2.6460e-08,  3.2999e-04,  2.3013e-04, -2.9198e-08,\n",
       "           2.2999e-04, -2.1572e-07,  6.7431e-05, -2.2279e-07],\n",
       "         [-2.6460e-08, -9.5428e-08,  2.3013e-04,  3.3003e-04, -9.5428e-08,\n",
       "           2.3003e-04, -1.5708e-07,  6.7483e-05, -1.8290e-07],\n",
       "         [-2.6390e-01, -2.6332e-01, -2.9198e-08, -9.5428e-08, -3.2027e-01,\n",
       "          -1.0380e-07,  8.3666e-02,  5.8348e-04,  5.8352e-04],\n",
       "         [-2.9198e-08, -9.5428e-08,  2.2999e-04,  2.3003e-04, -1.0380e-07,\n",
       "           6.7319e-04, -3.8906e-07,  1.6820e-04, -4.1677e-07],\n",
       "         [ 7.0188e-02,  7.0442e-02, -2.1572e-07, -1.5708e-07,  8.3666e-02,\n",
       "          -3.8906e-07,  1.3623e-03,  1.3936e-03,  1.3937e-03],\n",
       "         [ 1.2025e-04,  5.6173e-04,  6.7431e-05,  6.7483e-05,  5.8348e-04,\n",
       "           1.6820e-04,  1.3936e-03,  1.6519e-03,  1.5520e-03],\n",
       "         [ 1.2026e-04,  5.6176e-04, -2.2279e-07, -1.8290e-07,  5.8352e-04,\n",
       "          -4.1677e-07,  1.3937e-03,  1.5520e-03,  1.6521e-03]],\n",
       "        dtype=torch.float64)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in [mlt_result01, mlt_result02]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
